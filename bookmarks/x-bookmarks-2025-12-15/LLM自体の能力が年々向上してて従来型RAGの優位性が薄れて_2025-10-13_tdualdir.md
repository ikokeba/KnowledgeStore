---
tags:
  - AI
  - RAG
  - 機械学習
  - LLM
既読・整理済み: false
---
# tdual(ティーデュアル)@MatrixFlow

**Author:** @tdualdir
**Date:** 2025-10-13T12:38:03.000Z
**URL:** https://x.com/tdualdir/status/1977715454341722472
**Replies:** 1件（本人の返信）

---

## Content

LLM自体の能力が年々向上してて従来型RAGの優位性が薄れてきている中で、RAGの位置づけを改めて問い直し、RAG がうまく働く場合／失敗する場合を整理し、次RAGを単なる外部知識検索ではなくLLMの内部推論自己判断と協調する“適応的・補完的システムとした設計を提案した論文

## Links

- [arxiv.orgWhen Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented...Large Language Models (LLMs) have enabled a wide range of applications through their powerful capabilities in language understanding and generation. However, as LLMs are trained on static corpora,...](https://t.co/1XVn4seeVr)

## Replies (返信一覧)

### Reply 1 (返信数情報のみ)
**Info:** 返信数: 2件 (詳細はツイートページで確認してください)
**Note:** ブックマークページでは返信内容を表示できません。詳細はツイートページをご確認ください。

---

*Exported at: 12/15/2025, 10:44:14 PM*
